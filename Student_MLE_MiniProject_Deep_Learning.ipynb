{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mini Project: Deep Learning with Keras\n",
    "\n",
    "In this mini-project we'll be building a deep learning classifier using Keras to predict income from the popular [Adult Income dataset](http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html).\n",
    "\n",
    "Predicting income from demographic and socio-economic information is an important task with real-world applications, such as financial planning, market research, and social policy analysis. The Adult dataset, sometimes referred to as the \"Census Income\" dataset, contains a vast amount of anonymized data on individuals, including features such as age, education, marital status, occupation, and more. Our objective is to leverage this data to train a deep learning model that can effectively predict whether an individual's income exceeds $50,000 annually or not.\n",
    "\n",
    "Throughout this Colab, we will walk you through the entire process of building a deep learning classifier using Keras, a high-level neural network API that runs on top of TensorFlow. Keras is known for its user-friendly and intuitive interface, making it an excellent choice for both beginners and experienced deep learning practitioners.\n",
    "\n",
    "Here's a brief outline of what we will cover in this mini-project:\n",
    "\n",
    "1. **Data Preprocessing:** We will start by loading and exploring the Adult dataset.\n",
    "\n",
    "2. **Building the Deep Learning Model:** We will construct a neural network using Keras, where we'll dive into understanding the key components of a neural network, including layers, activation functions, and optimization algorithms.\n",
    "\n",
    "3. **Model Training:** With our model architecture in place, we will split the data into training and validation sets and train the neural network on the training data. We will monitor the training process to prevent overfitting and enhance generalization.\n",
    "\n",
    "4. **Model Evaluation:** After training, we'll assess the performance of our model on the test dataset.\n",
    "\n",
    "By the end of this tutorial, you will not only have a functional deep learning classifier for income prediction but also gain valuable insights into how to leverage the power of neural networks for solving real-world classification tasks.\n"
   ],
   "metadata": {
    "id": "fyXucUekO19i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install scikeras"
   ],
   "metadata": {
    "id": "rAGzXpBhHLPJ",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:33.320823Z",
     "start_time": "2024-11-03T19:10:33.315764Z"
    }
   },
   "execution_count": 393,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "id": "kLWR1DfQPakn",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:33.444593Z",
     "start_time": "2024-11-03T19:10:33.429800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can download the Adult data from the link [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data).\n",
    "\n",
    "Here are your tasks:\n",
    "\n",
    "  1. Load the Adult data into a Pandas Dataframe.\n",
    "  2. Ensure the dataset has properly named columns. If the columns are not read in, assign them by referencing the dataset documentation.\n",
    "  3. Display the first five rows of the dataset."
   ],
   "metadata": {
    "id": "5ymxgnyq86hE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_PATH = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "\n",
    "# Download the dataset and load it into a pandas DataFrame\n",
    "# Notes: file does not contain headers, those were added from the website data dictionary\n",
    "# there are spaces after the commas in the CSV that should be stripped out\n",
    "col_list = ['age','workclass','fnlweight','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']\n",
    "df = pd.read_csv(DATA_PATH, skipinitialspace=True, header=None, names=col_list)\n",
    "df"
   ],
   "metadata": {
    "id": "QmwdQy7pShig",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.160908Z",
     "start_time": "2024-11-03T19:10:33.446557Z"
    }
   },
   "execution_count": 395,
   "outputs": [
    {
     "data": {
      "text/plain": "       age         workclass  fnlweight   education  education-num  \\\n0       39         State-gov      77516   Bachelors             13   \n1       50  Self-emp-not-inc      83311   Bachelors             13   \n2       38           Private     215646     HS-grad              9   \n3       53           Private     234721        11th              7   \n4       28           Private     338409   Bachelors             13   \n...    ...               ...        ...         ...            ...   \n32556   27           Private     257302  Assoc-acdm             12   \n32557   40           Private     154374     HS-grad              9   \n32558   58           Private     151910     HS-grad              9   \n32559   22           Private     201490     HS-grad              9   \n32560   52      Self-emp-inc     287927     HS-grad              9   \n\n           marital-status         occupation   relationship   race     sex  \\\n0           Never-married       Adm-clerical  Not-in-family  White    Male   \n1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n...                   ...                ...            ...    ...     ...   \n32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n32558             Widowed       Adm-clerical      Unmarried  White  Female   \n32559       Never-married       Adm-clerical      Own-child  White    Male   \n32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n\n       capital-gain  capital-loss  hours-per-week native-country income  \n0              2174             0              40  United-States  <=50K  \n1                 0             0              13  United-States  <=50K  \n2                 0             0              40  United-States  <=50K  \n3                 0             0              40  United-States  <=50K  \n4                 0             0              40           Cuba  <=50K  \n...             ...           ...             ...            ...    ...  \n32556             0             0              38  United-States  <=50K  \n32557             0             0              40  United-States   >50K  \n32558             0             0              40  United-States  <=50K  \n32559             0             0              20  United-States  <=50K  \n32560         15024             0              40  United-States   >50K  \n\n[32561 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlweight</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>27</td>\n      <td>Private</td>\n      <td>257302</td>\n      <td>Assoc-acdm</td>\n      <td>12</td>\n      <td>Married-civ-spouse</td>\n      <td>Tech-support</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>154374</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>151910</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Widowed</td>\n      <td>Adm-clerical</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>22</td>\n      <td>Private</td>\n      <td>201490</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>52</td>\n      <td>Self-emp-inc</td>\n      <td>287927</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n<p>32561 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ],
   "metadata": {
    "id": "X1wSIzVtPrfL",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.176461Z",
     "start_time": "2024-11-03T19:10:34.162415Z"
    }
   },
   "execution_count": 396,
   "outputs": [
    {
     "data": {
      "text/plain": "   age         workclass  fnlweight  education  education-num  \\\n0   39         State-gov      77516  Bachelors             13   \n1   50  Self-emp-not-inc      83311  Bachelors             13   \n2   38           Private     215646    HS-grad              9   \n3   53           Private     234721       11th              7   \n4   28           Private     338409  Bachelors             13   \n\n       marital-status         occupation   relationship   race     sex  \\\n0       Never-married       Adm-clerical  Not-in-family  White    Male   \n1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n\n   capital-gain  capital-loss  hours-per-week native-country income  \n0          2174             0              40  United-States  <=50K  \n1             0             0              13  United-States  <=50K  \n2             0             0              40  United-States  <=50K  \n3             0             0              40  United-States  <=50K  \n4             0             0              40           Cuba  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlweight</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you're not already familiar with the Adult dataset, it's important to do some exploratory data analysis.\n",
    "\n",
    "Here are your tasks:\n",
    "\n",
    "  1. Do exploratory data analysis to give you some better intuition for the dataset. This is a bit open-ended. How many rows/columns are there? How are NULL values represented? What's the percentage of positive cases in the dataset?\n",
    "\n",
    "  2. Drop all rows with NULL values.\n",
    "\n",
    "  3. Use Scikit-Learn's [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to convert the `income` column with a data type string to a binary variable."
   ],
   "metadata": {
    "id": "5fHLuKZl9ivm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Do some exploratory analysis. How many rows/columns are there? How are NULL\n",
    "# values represented? What's the percentrage of positive cases in the dataset?\n",
    "print(df.info())"
   ],
   "metadata": {
    "id": "fc_s4kRKTloe",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.208089Z",
     "start_time": "2024-11-03T19:10:34.177971Z"
    }
   },
   "execution_count": 397,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlweight       32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlweight         0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.239712Z",
     "start_time": "2024-11-03T19:10:34.211096Z"
    }
   },
   "execution_count": 398
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Counts by column, as indicated by question marks in original data table:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   0\nage                0\nworkclass       1836\nfnlweight          0\neducation          0\neducation-num      0\nmarital-status     0\noccupation      1843\nrelationship       0\nrace               0\nsex                0\ncapital-gain       0\ncapital-loss       0\nhours-per-week     0\nnative-country   583\nincome             0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>workclass</th>\n      <td>1836</td>\n    </tr>\n    <tr>\n      <th>fnlweight</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>education-num</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>marital-status</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>occupation</th>\n      <td>1843</td>\n    </tr>\n    <tr>\n      <th>relationship</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>capital-gain</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>capital-loss</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>hours-per-week</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>native-country</th>\n      <td>583</td>\n    </tr>\n    <tr>\n      <th>income</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NULLs are represented by question mark strings: ?\n",
    "# So count the number of single question marks\n",
    "# first set up a totals dataframe and zero it out\n",
    "null_counts = pd.DataFrame(index=range(1), columns=df.columns)\n",
    "for col in null_counts:\n",
    "    null_counts[col].values[:] = 0\n",
    "    \n",
    "for col in df:\n",
    "    null_counts[col] = sum([1 for val in df[col] if type(val) == str and val.strip() == \"?\"])\n",
    "    \n",
    "print(\"Null Counts by column, as indicated by question marks in original data table:\")\n",
    "null_counts.T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.318442Z",
     "start_time": "2024-11-03T19:10:34.240712Z"
    }
   },
   "execution_count": 399
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dropping nulls (32561, 15)\n"
     ]
    }
   ],
   "source": [
    "# but that doesn't tell us how many unique rows have one or more nulls, so do it the mask way\n",
    "df_null_test = df == \"?\"\n",
    "df.mask(df_null_test, inplace=True)\n",
    "print(f\"shape before dropping nulls {df.shape}\")\n",
    "original_shape = df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.350026Z",
     "start_time": "2024-11-03T19:10:34.319447Z"
    }
   },
   "execution_count": 400
  },
  {
   "cell_type": "code",
   "source": [
    "# Find all NULL values and drop them\n",
    "df.dropna(inplace=True)\n",
    "clean_shape = df.shape\n",
    "print(f\"shape after dropping nulls {df.shape}\")\n",
    "print(f\"Percentage of non-null rows in the dataset is: {clean_shape[0]/original_shape[0]*100:0.0f}%\")\n"
   ],
   "metadata": {
    "id": "pZW7GRw3P0dT",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.382291Z",
     "start_time": "2024-11-03T19:10:34.351026Z"
    }
   },
   "execution_count": 401,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after dropping nulls (30162, 15)\n",
      "Percentage of non-null rows in the dataset is: 93%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Use Scikit-Learn's LabelEncoder to convert the income column with a data type\n",
    "# string to a binary variable.\n",
    "le = LabelEncoder()\n",
    "df['income_enc'] = le.fit_transform(df['income'])\n",
    "print(df.groupby('income_enc')['age'].count())\n",
    "print(df.info())\n",
    "\n",
    "fraction_positive = df['income_enc'].sum()/len(df['income_enc'])\n",
    "fraction_positive\n",
    "print(f\"Percentage of positive >=50k rows in the dataset is: {fraction_positive*100:0.0f}%\")\n"
   ],
   "metadata": {
    "id": "BZ_mJT_DLZ-L",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.413356Z",
     "start_time": "2024-11-03T19:10:34.383761Z"
    }
   },
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income_enc\n",
      "0    22654\n",
      "1     7508\n",
      "Name: age, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30162 entries, 0 to 32560\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             30162 non-null  int64 \n",
      " 1   workclass       30162 non-null  object\n",
      " 2   fnlweight       30162 non-null  int64 \n",
      " 3   education       30162 non-null  object\n",
      " 4   education-num   30162 non-null  int64 \n",
      " 5   marital-status  30162 non-null  object\n",
      " 6   occupation      30162 non-null  object\n",
      " 7   relationship    30162 non-null  object\n",
      " 8   race            30162 non-null  object\n",
      " 9   sex             30162 non-null  object\n",
      " 10  capital-gain    30162 non-null  int64 \n",
      " 11  capital-loss    30162 non-null  int64 \n",
      " 12  hours-per-week  30162 non-null  int64 \n",
      " 13  native-country  30162 non-null  object\n",
      " 14  income          30162 non-null  object\n",
      " 15  income_enc      30162 non-null  int64 \n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 3.9+ MB\n",
      "None\n",
      "Percentage of positive >=50k rows in the dataset is: 25%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Split the data into training and test sets. Remember not to include the label you're trying to predict, `income`, as a column in your training data."
   ],
   "metadata": {
    "id": "ibK0DxJsA1JH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Split dataset into training and test sets\n",
    "# Note: we can do this up front because later on the pipeline will apply the same transforms to both train and test sets equally \n",
    "y = df['income_enc'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['income','income_enc']), y, test_size=0.25, random_state=42, stratify=y)"
   ],
   "metadata": {
    "id": "1whzL6K7J-zq",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.444459Z",
     "start_time": "2024-11-03T19:10:34.414866Z"
    }
   },
   "execution_count": 403,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In machine learning, the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) metric are commonly used to evaluate the performance of binary classification models. These are valuable tools for understanding how well a model can distinguish between the positive and negative classes in a classification problem.\n",
    "\n",
    "Let's break down each concept:\n",
    "\n",
    "1. ROC Curve:\n",
    "The ROC curve is a graphical representation of a binary classifier's performance as the discrimination threshold is varied. It is created by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at different threshold values. Here's how these rates are calculated:\n",
    "\n",
    "- True Positive Rate (TPR), also called Sensitivity or Recall, measures the proportion of actual positive instances that are correctly identified by the model:\n",
    "   TPR = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "- False Positive Rate (FPR) measures the proportion of actual negative instances that are incorrectly classified as positive by the model:\n",
    "   FPR = False Positives / (False Positives + True Negatives)\n",
    "\n",
    "The ROC curve is useful because it shows how well a classifier can trade off between sensitivity and specificity across different threshold values. The ideal ROC curve hugs the top-left corner, indicating a high TPR and low FPR, meaning the classifier is excellent at distinguishing between the two classes.\n",
    "\n",
    "2. AUC (Area Under the Curve):\n",
    "The AUC is a scalar metric derived from the ROC curve. It represents the area under the ROC curve, hence its name. The AUC ranges from 0 to 1, where 0 indicates a very poor classifier (always predicting the opposite class) and 1 signifies a perfect classifier (making all correct predictions).\n",
    "\n",
    "The AUC metric is beneficial because it provides a single value to summarize the classifier's overall performance across all possible threshold values. It is particularly useful when dealing with imbalanced datasets, where one class significantly outnumbers the other. In such cases, accuracy alone might not be a reliable evaluation metric, and AUC can provide a more robust performance measure.\n",
    "\n",
    "A quick rule of thumb for interpreting AUC values:\n",
    "- AUC ≈ 0.5: The model performs no better than random guessing.\n",
    "- 0.5 < AUC < 0.7: The model has poor to fair performance.\n",
    "- 0.7 < AUC < 0.9: The model has good to excellent performance.\n",
    "- AUC ≈ 1: The model is close to or has a perfect performance."
   ],
   "metadata": {
    "id": "HMsXM6B_BX5k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are your tasks:\n",
    "\n",
    "  1. Use Scikit-Learn's [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) to calculate the AUC score for a method that always predicts the majority class.  "
   ],
   "metadata": {
    "id": "NDGgBVEKEYKi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use Scikit-Learn's roc_auc_score to calculate the AUC score for a method that\n",
    "# always predicts the majority class.\n",
    "\n",
    "# zero rule algorithm for a classification problem\n",
    "def predict_majority_class(a_ytrain, a_ytest):\n",
    "    count_0, count_1 = np.bincount(a_ytrain, minlength=2)\n",
    "    if count_0 > count_1: \n",
    "        majority_class = 0\n",
    "    else:\n",
    "        majority_class = 1\n",
    "    print(f\"Majority class for this problem is {majority_class}, of the set {set(a_ytrain)}, with {count_0} zeros and {count_1} ones\")\n",
    "    predicted = np.empty(len(a_ytest))\n",
    "    predicted.fill(majority_class)\n",
    "    return predicted\n",
    "    \n",
    "baseline_pred = predict_majority_class(y_train, y_test)\n",
    "baseline_roc_auc = roc_auc_score(y_test, baseline_pred)\n",
    "\n",
    "print(f\"Baseline zero rule algorithm returned shape: {baseline_pred.shape} and ROC/AUC score of {baseline_roc_auc}\")"
   ],
   "metadata": {
    "id": "s00Xs8bqUZnn",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:34.460503Z",
     "start_time": "2024-11-03T19:10:34.446964Z"
    }
   },
   "execution_count": 404,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class for this problem is 0, of the set {np.int64(0), np.int64(1)}, with 16990 zeros and 5631 ones\n",
      "Baseline zero rule algorithm returned shape: (7541,) and ROC/AUC score of 0.5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's do a little feature engineering.\n",
    "\n",
    "1. Use Scikit-Learn's [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to apply One Hot Encoding to the categorical variables in `workclass`, `education`, `marital-status`, `occupation`, `relationship`, 'race', `sex`, and `native-country`. Also, apply [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) to the remaining continuous features. How many columns will the dataframe have after these columns transformations are applied?"
   ],
   "metadata": {
    "id": "uWSiYNarF2t_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use Scikit-Learn's ColumnTransformer to apply One Hot Encoding to the\n",
    "# categorical variables in workclass, education, marital-status, occupation,\n",
    "# relationship, 'race', sex, and native-country.\n",
    "# Also, apply MinMaxScaler to\n",
    "# the remaining continuous features.\n",
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False).set_output(transform='pandas')\n",
    "\n",
    "numerical_cols = ['age','fnlweight','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "\n",
    "num_df = df.drop(columns=categorical_cols+['income', 'income_enc'])\n",
    "\n",
    "mms = MinMaxScaler().set_output(transform='pandas')\n",
    "\n",
    "#clean_df = pd.concat([num_df, cat_df], axis=1)\n",
    "#clean_df\n",
    "preproc = ColumnTransformer(transformers=[\n",
    "        (\"cats\", ohe, categorical_cols),\n",
    "        (\"nums\", mms, numerical_cols)],\n",
    "    verbose=True,\n",
    "    n_jobs=-1\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "preproc.fit_transform(df)\n"
   ],
   "metadata": {
    "id": "4DybgGJyW-3Q",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:40.598061Z",
     "start_time": "2024-11-03T19:10:34.461505Z"
    }
   },
   "execution_count": 405,
   "outputs": [
    {
     "data": {
      "text/plain": "       cats__workclass_Local-gov  cats__workclass_Private  \\\n0                            0.0                      0.0   \n1                            0.0                      0.0   \n2                            0.0                      1.0   \n3                            0.0                      1.0   \n4                            0.0                      1.0   \n...                          ...                      ...   \n32556                        0.0                      1.0   \n32557                        0.0                      1.0   \n32558                        0.0                      1.0   \n32559                        0.0                      1.0   \n32560                        0.0                      0.0   \n\n       cats__workclass_Self-emp-inc  cats__workclass_Self-emp-not-inc  \\\n0                               0.0                               0.0   \n1                               0.0                               1.0   \n2                               0.0                               0.0   \n3                               0.0                               0.0   \n4                               0.0                               0.0   \n...                             ...                               ...   \n32556                           0.0                               0.0   \n32557                           0.0                               0.0   \n32558                           0.0                               0.0   \n32559                           0.0                               0.0   \n32560                           1.0                               0.0   \n\n       cats__workclass_State-gov  cats__workclass_Without-pay  \\\n0                            1.0                          0.0   \n1                            0.0                          0.0   \n2                            0.0                          0.0   \n3                            0.0                          0.0   \n4                            0.0                          0.0   \n...                          ...                          ...   \n32556                        0.0                          0.0   \n32557                        0.0                          0.0   \n32558                        0.0                          0.0   \n32559                        0.0                          0.0   \n32560                        0.0                          0.0   \n\n       cats__education_11th  cats__education_12th  cats__education_1st-4th  \\\n0                       0.0                   0.0                      0.0   \n1                       0.0                   0.0                      0.0   \n2                       0.0                   0.0                      0.0   \n3                       1.0                   0.0                      0.0   \n4                       0.0                   0.0                      0.0   \n...                     ...                   ...                      ...   \n32556                   0.0                   0.0                      0.0   \n32557                   0.0                   0.0                      0.0   \n32558                   0.0                   0.0                      0.0   \n32559                   0.0                   0.0                      0.0   \n32560                   0.0                   0.0                      0.0   \n\n       cats__education_5th-6th  ...  cats__native-country_Trinadad&Tobago  \\\n0                          0.0  ...                                   0.0   \n1                          0.0  ...                                   0.0   \n2                          0.0  ...                                   0.0   \n3                          0.0  ...                                   0.0   \n4                          0.0  ...                                   0.0   \n...                        ...  ...                                   ...   \n32556                      0.0  ...                                   0.0   \n32557                      0.0  ...                                   0.0   \n32558                      0.0  ...                                   0.0   \n32559                      0.0  ...                                   0.0   \n32560                      0.0  ...                                   0.0   \n\n       cats__native-country_United-States  cats__native-country_Vietnam  \\\n0                                     1.0                           0.0   \n1                                     1.0                           0.0   \n2                                     1.0                           0.0   \n3                                     1.0                           0.0   \n4                                     0.0                           0.0   \n...                                   ...                           ...   \n32556                                 1.0                           0.0   \n32557                                 1.0                           0.0   \n32558                                 1.0                           0.0   \n32559                                 1.0                           0.0   \n32560                                 1.0                           0.0   \n\n       cats__native-country_Yugoslavia  nums__age  nums__fnlweight  \\\n0                                  0.0   0.301370         0.043338   \n1                                  0.0   0.452055         0.047277   \n2                                  0.0   0.287671         0.137244   \n3                                  0.0   0.493151         0.150212   \n4                                  0.0   0.150685         0.220703   \n...                                ...        ...              ...   \n32556                              0.0   0.136986         0.165563   \n32557                              0.0   0.315068         0.095589   \n32558                              0.0   0.561644         0.093914   \n32559                              0.0   0.068493         0.127620   \n32560                              0.0   0.479452         0.186383   \n\n       nums__education-num  nums__capital-gain  nums__capital-loss  \\\n0                 0.800000            0.021740                 0.0   \n1                 0.800000            0.000000                 0.0   \n2                 0.533333            0.000000                 0.0   \n3                 0.400000            0.000000                 0.0   \n4                 0.800000            0.000000                 0.0   \n...                    ...                 ...                 ...   \n32556             0.733333            0.000000                 0.0   \n32557             0.533333            0.000000                 0.0   \n32558             0.533333            0.000000                 0.0   \n32559             0.533333            0.000000                 0.0   \n32560             0.533333            0.150242                 0.0   \n\n       nums__hours-per-week  \n0                  0.397959  \n1                  0.122449  \n2                  0.397959  \n3                  0.397959  \n4                  0.397959  \n...                     ...  \n32556              0.377551  \n32557              0.397959  \n32558              0.397959  \n32559              0.193878  \n32560              0.397959  \n\n[30162 rows x 96 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cats__workclass_Local-gov</th>\n      <th>cats__workclass_Private</th>\n      <th>cats__workclass_Self-emp-inc</th>\n      <th>cats__workclass_Self-emp-not-inc</th>\n      <th>cats__workclass_State-gov</th>\n      <th>cats__workclass_Without-pay</th>\n      <th>cats__education_11th</th>\n      <th>cats__education_12th</th>\n      <th>cats__education_1st-4th</th>\n      <th>cats__education_5th-6th</th>\n      <th>...</th>\n      <th>cats__native-country_Trinadad&amp;Tobago</th>\n      <th>cats__native-country_United-States</th>\n      <th>cats__native-country_Vietnam</th>\n      <th>cats__native-country_Yugoslavia</th>\n      <th>nums__age</th>\n      <th>nums__fnlweight</th>\n      <th>nums__education-num</th>\n      <th>nums__capital-gain</th>\n      <th>nums__capital-loss</th>\n      <th>nums__hours-per-week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.301370</td>\n      <td>0.043338</td>\n      <td>0.800000</td>\n      <td>0.021740</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.452055</td>\n      <td>0.047277</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.122449</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.287671</td>\n      <td>0.137244</td>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.493151</td>\n      <td>0.150212</td>\n      <td>0.400000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.150685</td>\n      <td>0.220703</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.136986</td>\n      <td>0.165563</td>\n      <td>0.733333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.377551</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.315068</td>\n      <td>0.095589</td>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.561644</td>\n      <td>0.093914</td>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.068493</td>\n      <td>0.127620</td>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.193878</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.479452</td>\n      <td>0.186383</td>\n      <td>0.533333</td>\n      <td>0.150242</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n    </tr>\n  </tbody>\n</table>\n<p>30162 rows × 96 columns</p>\n</div>"
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# How many columns will the dataframe have after these columns transformations are applied?\n",
    "print(f\"Encoded and Scaled data frame now has {len(preproc.get_feature_names_out())} columns, excluding the target.\")\n"
   ],
   "metadata": {
    "id": "emfaqHwvKfLU",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:40.613405Z",
     "start_time": "2024-11-03T19:10:40.599025Z"
    }
   },
   "execution_count": 406,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded and Scaled data frame now has 96 columns, excluding the target.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keras is an open-source deep learning library written in Python. It was developed to provide a user-friendly, high-level interface for building and training neural networks. The library was created by François Chollet and was first released in March 2015 as part of the Deeplearning4j project. Later, it became part of the TensorFlow ecosystem and is now the official high-level API for TensorFlow.\n",
    "\n",
    "Keras is designed to be modular, user-friendly, and easy to extend. It allows researchers and developers to quickly prototype and experiment with various deep learning models. One of the primary goals of Keras is to enable fast experimentation, making it simple to build and iterate on different architectures.\n",
    "\n",
    "Key features of Keras include:\n",
    "\n",
    "1. User-friendly API: Keras provides a simple and intuitive interface for defining and training deep learning models. Its design philosophy focuses on ease of use and clarity of code.\n",
    "\n",
    "2. Modularity: Models in Keras are built as a sequence of layers, and users can easily stack, merge, or create complex architectures using a wide range of predefined layers.\n",
    "\n",
    "3. Extensibility: Keras allows users to define custom layers, loss functions, and metrics. This flexibility enables researchers to experiment with new ideas and algorithms seamlessly.\n",
    "\n",
    "4. Backends: Initially, Keras supported multiple backends, including TensorFlow, Theano, and CNTK. However, as of TensorFlow version 2.0, TensorFlow has become the primary backend for Keras.\n",
    "\n",
    "5. Multi-GPU and distributed training: Keras supports training models on multiple GPUs and in distributed computing environments, making it suitable for large-scale experiments.\n",
    "\n",
    "6. Pre-trained models: Keras includes a collection of pre-trained models for common tasks, such as image classification (e.g., VGG, ResNet, MobileNet) and natural language processing (e.g., Word2Vec, GloVe).\n",
    "\n",
    "The integration of Keras into TensorFlow as its official high-level API has solidified its position as one of the most popular deep learning libraries in the machine learning community. Its ease of use and versatility have contributed to its widespread adoption in both academia and industry for a wide range of deep learning tasks."
   ],
   "metadata": {
    "id": "AtoqTz5rGuET"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are your tasks:\n",
    "\n",
    "1. Create your own model in Keras to predict income in the Adult training data. Remember, it's always better to start simple and add complexity to the model if necessary. What's a good loss function to use?\n",
    "\n",
    "2. Keras can be integrated with Scitkit-Learn using a wrapper. Use the [KerasClassifier wrapper](https://adriangb.com/scikeras/stable/generated/scikeras.wrappers.KerasClassifier.html) to integrate your Keras model with the ColumnTransformer from previous steps using a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object.\n",
    "\n",
    "3. Fit your model.\n",
    "\n",
    "4. Calculate the AUC score of your model on the test data. Does the model predict better than random?\n",
    "\n",
    "5. Generate an ROC curve for your model using [RocCurveDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html). What would the curve look like if all your predictions were randomly generated? What would the curve look like if it you had a perfect model?"
   ],
   "metadata": {
    "id": "HVUa0h83HU24"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Keras model\n",
    "# Tried with sigmoid activation and sgd optimizer, but couldn't get an AUC score better than 0.75, this combo is 2 points better.\n",
    "model = Sequential([\n",
    "    Input(shape=(96,) ),                # Using input because Python 3.9 tensorflow.keras complains the other ways\n",
    "    Dense(12, activation='relu'),    # Hidden layer for experimenting; tried 24 nodes, and similar result as 12\n",
    "    Dense(8, activation='relu'),    # Hidden layer for experimenting; having a 2nd hidden layer doesn't seem to do much to improve accuracy\n",
    "    Dense(1, activation='relu')      # Output layer needs to be 1 value to match the target dimension\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ],
   "metadata": {
    "id": "h2xIpLlXQEcx",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:40.954144Z",
     "start_time": "2024-11-03T19:10:40.614410Z"
    }
   },
   "execution_count": 407,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_35\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_35\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_91 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m)             │         \u001B[38;5;34m1,164\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_92 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │           \u001B[38;5;34m104\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_93 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m9\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,164</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,277\u001B[0m (4.99 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,277</span> (4.99 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,277\u001B[0m (4.99 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,277</span> (4.99 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a Keras classifier\n",
    "# note: this is the wrapper class that the keras model goes in to fit into the SciKit Learn Pipeline framework\n",
    "#   where SciKit Learn classifiers can use the set_params() notation to pass classifier specific arguments, for Keras, they are set in the constructor\n",
    "clf = KerasClassifier(model=model, epochs=100, verbose=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:40.969738Z",
     "start_time": "2024-11-03T19:10:40.955144Z"
    }
   },
   "execution_count": 408
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the scikit-learn pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preproc),\n",
    "        (\"nnet\", clf)],\n",
    "    verbose=True)\n"
   ],
   "metadata": {
    "id": "VKxkil7QQJ6n",
    "ExecuteTime": {
     "end_time": "2024-11-03T19:10:40.985624Z",
     "start_time": "2024-11-03T19:10:40.970739Z"
    }
   },
   "execution_count": 409,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print(f\"Final acccuracy: {accuracy}\")"
   ],
   "metadata": {
    "id": "25O8ZLleGQnk",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-03T19:10:40.987135Z"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   1.7s\n",
      "Epoch 1/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 708us/step - accuracy: 0.7902 - loss: 0.7910\n",
      "Epoch 2/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 686us/step - accuracy: 0.8276 - loss: 0.3889\n",
      "Epoch 3/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 715us/step - accuracy: 0.8420 - loss: 0.3583\n",
      "Epoch 4/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - accuracy: 0.8396 - loss: 0.3522\n",
      "Epoch 5/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 727us/step - accuracy: 0.8405 - loss: 0.3531\n",
      "Epoch 6/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 687us/step - accuracy: 0.8393 - loss: 0.3454\n",
      "Epoch 7/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - accuracy: 0.8435 - loss: 0.3434\n",
      "Epoch 8/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 680us/step - accuracy: 0.8428 - loss: 0.3508\n",
      "Epoch 9/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 683us/step - accuracy: 0.8472 - loss: 0.3409\n",
      "Epoch 10/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 686us/step - accuracy: 0.8435 - loss: 0.3487\n",
      "Epoch 11/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 687us/step - accuracy: 0.8455 - loss: 0.3355\n",
      "Epoch 12/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 683us/step - accuracy: 0.8469 - loss: 0.3372\n",
      "Epoch 13/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - accuracy: 0.8518 - loss: 0.3319\n",
      "Epoch 14/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 692us/step - accuracy: 0.8510 - loss: 0.3254\n",
      "Epoch 15/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - accuracy: 0.8469 - loss: 0.3261\n",
      "Epoch 16/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - accuracy: 0.8506 - loss: 0.3324\n",
      "Epoch 17/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 681us/step - accuracy: 0.8469 - loss: 0.3303\n",
      "Epoch 18/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - accuracy: 0.8493 - loss: 0.3338\n",
      "Epoch 19/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 689us/step - accuracy: 0.8519 - loss: 0.3243\n",
      "Epoch 20/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - accuracy: 0.8544 - loss: 0.3161\n",
      "Epoch 21/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 684us/step - accuracy: 0.8518 - loss: 0.3219\n",
      "Epoch 22/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - accuracy: 0.8498 - loss: 0.3277\n",
      "Epoch 23/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - accuracy: 0.8519 - loss: 0.3255\n",
      "Epoch 24/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - accuracy: 0.8567 - loss: 0.3318\n",
      "Epoch 25/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 713us/step - accuracy: 0.8560 - loss: 0.3179\n",
      "Epoch 26/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 708us/step - accuracy: 0.8553 - loss: 0.3221\n",
      "Epoch 27/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - accuracy: 0.8536 - loss: 0.3188\n",
      "Epoch 28/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 681us/step - accuracy: 0.8465 - loss: 0.3331\n",
      "Epoch 29/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 705us/step - accuracy: 0.8520 - loss: 0.3267\n",
      "Epoch 30/100\n",
      "\u001B[1m707/707\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 682us/step - accuracy: 0.8460 - loss: 0.3312\n",
      "Epoch 31/100\n",
      "\u001B[1m345/707\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 657us/step - accuracy: 0.8518 - loss: 0.3127"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the AUC score of your model on the test data.\n",
    "# Does the model predict better than random? - Answer: yes, my random test only yielded 50%, so 77% AUC is a better score\n",
    "y_pred = pipe.predict(X_test)\n",
    "nn_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Final trained neural network AUC score: {nn_auc}\")"
   ],
   "metadata": {
    "id": "SLcNQGVqNYbB",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate an ROC curve for your model.\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred)\n"
   ],
   "metadata": {
    "id": "prJG9pr7PYIc",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
